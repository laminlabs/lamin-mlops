{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "[![](https://img.shields.io/badge/Source%20on%20GitHub-orange)](https://github.com/laminlabs/lamin-mlops/blob/main/docs/mlflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "We show how LaminDB can be integrated with [MLflow](https://mlflow.org/) to track model checkpoints as artifacts linked against training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# pip install lamindb torchvision lightning wandb\n",
    "!lamin init --storage ./lamin-mlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import lightning as pl\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "\n",
    "from torch import utils\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from autoencoder import LitAutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "```{dropdown} Tracking models in both LaminDB and MLFlow\n",
    "It is not always necessary to track all model parameters and metrics in both LaminDB and MLFlow.\n",
    "However, if specific artifacts or runs should be queryable by specific model attributes such as, for example, the learning rate, then these attributes should be tracked.\n",
    "Below, we show exemplary how to do that for the batch size and learning rate but the approach generalizes to more features.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model run parameters, features, and labels so that validation passes later on\n",
    "MODEL_CONFIG = {\"batch_size\": 32, \"lr\": 0.001}\n",
    "\n",
    "hyperparameter = ln.Feature(name=\"Autoencoder hyperparameter\", is_type=True).save()\n",
    "hyperparams = ln.Feature.from_dict(MODEL_CONFIG, feature_type=hyperparameter)\n",
    "ln.save(hyperparams)\n",
    "\n",
    "metrics_to_annotate = [\"train_loss\", \"val_loss\", \"current_epoch\"]\n",
    "for metric in metrics_to_annotate:\n",
    "    dtype = int if metric == \"current_epoch\" else float\n",
    "    ln.Feature(name=metric, dtype=dtype).save()\n",
    "\n",
    "# create all MLflow related features like 'mlflow_run_id'\n",
    "_ = ln.examples.ml_tracking.create_mlflow_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# track this notebook/script run so that all checkpoint artifacts are associated with the source code\n",
    "ln.track(params=MODEL_CONFIG, project=ln.Project(name=\"MLflow tutorial\").save())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Define a model\n",
    "\n",
    "We use a basic PyTorch Lightning autoencoder as an example model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "````{dropdown} Code of LitAutoEncoder\n",
    "```{eval-rst}\n",
    ".. literalinclude:: autoencoder.py\n",
    "   :language: python\n",
    "   :caption: Simple autoencoder model\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Query & download the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "We saved the MNIST dataset in a [curation notebook](/mnist) which now shows up in the Artifact registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(kind=\"dataset\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Let's get the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "artifact = ln.Artifact.get(key=\"testdata/mnist\")\n",
    "artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "And download it to a local cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "path = artifact.cache()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Create a PyTorch-compatible dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = MNIST(path.as_posix(), transform=ToTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Monitor training with MLflow\n",
    "\n",
    "Train our example model and track the training progress with `MLflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# enable MLFlow PyTorch autologging\n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as mlflow_run:\n",
    "    train_dataset = MNIST(\n",
    "        root=\"./data\", train=True, download=True, transform=ToTensor()\n",
    "    )\n",
    "    val_dataset = MNIST(root=\"./data\", train=False, download=True, transform=ToTensor())\n",
    "    train_loader = utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "    val_loader = utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "    # create model\n",
    "    autoencoder = LitAutoEncoder(hidden_size=32, bottleneck_size=16)\n",
    "\n",
    "    # Create a LaminDB LightningCallback which also (optionally) annotates checkpoints by desired metrics\n",
    "    lamindb_callback = ln.integrations.lightning.Callback(\n",
    "        path=Path(\"model_checkpoints\") / \"{mlflow_run.info.run_id}_last_epoch.ckpt\",\n",
    "        key=f\"testmodels/mlflow/{mlflow_run.info.run_id}.ckpt\",\n",
    "        features={\n",
    "            \"mlflow_run_id\": mlflow_run.info.run_id,\n",
    "            \"mlflow_run_name\": mlflow_run.info.run_name,\n",
    "            **{\n",
    "                metric: None for metric in metrics_to_annotate\n",
    "            },  # auto-populated through callback\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    trainer = pl.Trainer(\n",
    "        limit_train_batches=3,\n",
    "        max_epochs=5,\n",
    "        callbacks=[lamindb_callback],\n",
    "    )\n",
    "    trainer.fit(\n",
    "        model=autoencoder, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    "    )\n",
    "\n",
    "    # Register model_summary.txt\n",
    "    local_model_summary_path = (\n",
    "        f\"{mlflow_run.info.artifact_uri.removeprefix('file://')}/model_summary.txt\"\n",
    "    )\n",
    "    mlflow_model_summary_af = ln.Artifact(\n",
    "        local_model_summary_path,\n",
    "        key=local_model_summary_path,\n",
    "        kind=\"model\",\n",
    "    ).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## MLflow and LaminDB user interfaces together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**MLflow and LaminDB runs:**\n",
    "\n",
    "Both MLflow and LaminDB capture any runs together with run parameters.\n",
    "\n",
    "| MLFlow experiment overview | LaminHub run overview |\n",
    "| ------- | ------- |\n",
    "| [![MLFlow experiment overview UI](https://lamin-site-assets.s3.amazonaws.com/.lamindb/n0xxFoMRtZPiQ7VT0003.png)](https://lamin-site-assets.s3.amazonaws.com/.lamindb/n0xxFoMRtZPiQ7VT0003.png) | [![LaminHub run UI](https://lamin-site-assets.s3.amazonaws.com/.lamindb/aBXksZMr2VkX7Mfr0000.png)](https://lamin-site-assets.s3.amazonaws.com/.lamindb/aBXksZMr2VkX7Mfr0000.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "**MLflow run details and LaminDB artifact details:**\n",
    "\n",
    "MLflow and LaminDB complement each other.\n",
    "Whereas MLflow is excellent at capturing metrics over time, LaminDB excells at capturing lineage of input & output data and training checkpoints.\n",
    "\n",
    "| MLFlow run view | LaminHub lineage view |\n",
    "| ------------- | ------------------ |\n",
    "| [![MLFlow runs](https://lamin-site-assets.s3.amazonaws.com/.lamindb/C0seowxsq4Du2B4T0002.png)](https://lamin-site-assets.s3.amazonaws.com/.lamindb/C0seowxsq4Du2B4T0002.png) | [![Laminhub lineage lineage](https://lamin-site-assets.s3.amazonaws.com/.lamindb/jLceaXyQf6WrFggW0000.png)](https://lamin-site-assets.s3.amazonaws.com/.lamindb/jLceaXyQf6WrFggW0000.png) |\n",
    "\n",
    "Both frameworks display output artifacts that were generated during the run.\n",
    "LaminDB further captures input artifacts, their origin and the associated source code.\n",
    "\n",
    "| MLFlow artifact view | LaminHub artifact view |\n",
    "| ------------- | --------------------- |\n",
    "| [![MLFlow artifact UI](https://lamin-site-assets.s3.amazonaws.com/.lamindb/k3ULj2AACQPASmUQ0000.png)](https://lamin-site-assets.s3.amazonaws.com/.lamindb/k3ULj2AACQPASmUQ0000.png) | [![LaminHub artifact UI](https://lamin-site-assets.s3.amazonaws.com/.lamindb/CQam6FY4V6DW65ek0000.png)](https://lamin-site-assets.s3.amazonaws.com/.lamindb/CQam6FY4V6DW65ek0000.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "All checkpoints are automatically annotated by the specified training metrics and MLflow run ID & name to keep both frameworks in sync:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "last_checkpoint_af = ln.Artifact.filter(\n",
    "    key__startswith=\"testmodels/mlflow/\", suffix__endswith=\"ckpt\", is_latest=True\n",
    ").last()\n",
    "last_checkpoint_af.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "To reuse the checkpoint later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "last_checkpoint_af.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint_af.view_lineage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamindb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
