{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "[![](https://img.shields.io/badge/Source%20on%20GitHub-orange)](https://github.com/laminlabs/lamin-mlops/blob/main/docs/mlflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "We show how LaminDB can be integrated with [MLflow](https://mlflow.org/) to track the training process and associate datasets & parameters with models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# pip install lamindb torchvision lightning wandb\n",
    "!lamin init --storage ./lamin-mlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import lightning as pl\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "\n",
    "from torch import utils\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from autoencoder import LitAutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "```{dropdown} Tracking models in both LaminDB and MLFlow\n",
    "It is not always necessary to track all model parameters and metrics in both LaminDB and MLFlow.\n",
    "However, if specific artifacts or runs should be queryable by specific model attributes such as, for example, the learning rate, then these attributes should be tracked.\n",
    "Below, we show exemplary how to do that for the batch size and learning rate but the approach generalizes to more features.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# define model run parameters & features\n",
    "MODEL_CONFIG = {\"batch_size\": 32, \"lr\": 0.001}\n",
    "\n",
    "hyperparameter = ln.Feature(name=\"Autoencoder hyperparameter\", is_type=True).save()\n",
    "hyperparams = ln.Feature.from_dict(MODEL_CONFIG, str_as_cat=True)\n",
    "for param in hyperparams:\n",
    "    param.type = hyperparameter\n",
    "    param.save()\n",
    "\n",
    "ln.track(params=MODEL_CONFIG, project=ln.Project(name=\"MLflow tutorial\").save())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Define a model\n",
    "\n",
    "We use a basic PyTorch Lightning autoencoder as an example model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "````{dropdown} Code of LitAutoEncoder\n",
    "```{eval-rst}\n",
    ".. literalinclude:: autoencoder.py\n",
    "   :language: python\n",
    "   :caption: Simple autoencoder model\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Query & download the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "We saved the MNIST dataset in a [curation notebook](/mnist) which now shows up in the Artifact registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(kind=\"dataset\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Let's get the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "artifact = ln.Artifact.get(key=\"testdata/mnist\")\n",
    "artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "And download it to a local cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "path = artifact.cache()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Create a PyTorch-compatible dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = MNIST(path.as_posix(), transform=ToTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Monitor training with MLflow\n",
    "\n",
    "Train our example model and track the training progress with `MLflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# enable MLFlow PyTorch autologging\n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from lamindb.integrations import lightning as lnpl\n",
    "\n",
    "with mlflow.start_run() as mlflow_run:\n",
    "    train_dataset = MNIST(\n",
    "        root=\"./data\", train=True, download=True, transform=ToTensor()\n",
    "    )\n",
    "    val_dataset = MNIST(root=\"./data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "    train_loader = utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "    val_loader = utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "    autoencoder = LitAutoEncoder(32, 16)\n",
    "\n",
    "    ckpt_dir = Path(\"model_checkpoints\")\n",
    "    ckpt_filename = \"{mlflow_run.info.run_id}_last_epoch.ckpt\"\n",
    "    artifact_key = f\"testmodels/mlflow/{mlflow_run.info.run_id}.ckpt\"  # every run makes a new version of this artifact\n",
    "\n",
    "    metrics = [\n",
    "        (\"epoch\", int),\n",
    "        (\"global_step\", int),\n",
    "        (\"train_loss\", float),\n",
    "        (\"train_loss_step\", float),\n",
    "        (\"val_loss\", float),\n",
    "        (\"val_loss_step\", float),\n",
    "    ]\n",
    "\n",
    "    # Create a LaminDB LightningCallback which also annotates check points by desired metrics\n",
    "    metrics_to_annotate = [\"train_loss\", \"val_loss\"]\n",
    "    for metric in metrics_to_annotate:\n",
    "        ln.Feature(name=metric, dtype=float).save()\n",
    "    lamindb_callback = lnpl.LightningCallback(\n",
    "        path=ckpt_dir / ckpt_filename, key=artifact_key, annotate_by=metrics_to_annotate\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"cpu\",\n",
    "        limit_train_batches=3,\n",
    "        max_epochs=5,\n",
    "        callbacks=[lamindb_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        model=autoencoder, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    "    )\n",
    "\n",
    "    # Register model_summary.txt\n",
    "    local_model_summary_path = (\n",
    "        f\"{mlflow_run.info.artifact_uri.removeprefix('file://')}/model_summary.txt\"\n",
    "    )\n",
    "    mlflow_model_summary_af = ln.Artifact(\n",
    "        local_model_summary_path,\n",
    "        key=local_model_summary_path,\n",
    "        kind=\"model\",\n",
    "    ).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "**See the training progress in the `mlflow` UI:**\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/C0seowxsq4Du2B4T0001.png\" alt=\"MLFlow run UI\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "**See the experiment overview:**\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/n0xxFoMRtZPiQ7VT0002.png\" alt=\"MLFlow experiment overview UI\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "last_checkpoint_af = ln.Artifact.get(\n",
    "    key__startswith=\"testmodels/mlflow/\", suffix__endswith=\"ckpt\", is_latest=True\n",
    ")\n",
    "last_checkpoint_af.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "If later on, you want to re-use the checkpoint, you can get it via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "last_checkpoint_af.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint_af.view_lineage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamindb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
