{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "[![](https://img.shields.io/badge/Source%20on%20GitHub-orange)](https://github.com/laminlabs/lamin-mlops/blob/main/docs/mlflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "We show how LaminDB can be integrated with [MLflow](https://mlflow.org/) to track the training process and associate datasets & parameters with models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# pip install lamindb torchvision lightning wandb\n",
    "!lamin init --storage ./lamin-mlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import lightning as pl\n",
    "import mlflow\n",
    "\n",
    "from pathlib import Path\n",
    "from torch import utils\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from autoencoder import LitAutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "```{dropdown} Tracking models in both LaminDB and MLFlow\n",
    "It is not always necessary to track all model parameters and metrics in both LaminDB and MLFlow.\n",
    "However, if specific artifacts or runs should be queryable by specific model attributes such as, for example, the learning rate, then these attributes should be tracked.\n",
    "Below, we show exemplary how to do that for the batch size and learning rate but the approach generalizes to more features.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# define model run parameters & features\n",
    "MODEL_CONFIG = {\"batch_size\": 32, \"lr\": 0.001}\n",
    "\n",
    "hyperparameter = ln.Feature(name=\"Autoencoder hyperparameter\", is_type=True).save()\n",
    "hyperparams = ln.Feature.from_dict(MODEL_CONFIG, str_as_cat=True)\n",
    "for param in hyperparams:\n",
    "    param.type = hyperparameter\n",
    "    param.save()\n",
    "\n",
    "ln.track(params=MODEL_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Define a model\n",
    "\n",
    "We use a basic PyTorch Lightning autoencoder as an example model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "````{dropdown} Code of LitAutoEncoder\n",
    "```{eval-rst}\n",
    ".. literalinclude:: autoencoder.py\n",
    "   :language: python\n",
    "   :caption: Simple autoencoder model\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Query & download the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "We saved the MNIST dataset in a [curation notebook](/mnist) which now shows up in the Artifact registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(kind=\"dataset\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Let's get the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "artifact = ln.Artifact.get(key=\"testdata/mnist\")\n",
    "artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "And download it to a local cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "path = artifact.cache()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Create a PyTorch-compatible dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = MNIST(path.as_posix(), transform=ToTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Monitor training with MLflow\n",
    "\n",
    "Train our example model and track the training progress with `MLflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# enable MLFlow PyTorch autologging\n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaminDBCheckpointCallback(pl.Callback):\n",
    "    \"\"\"A PyTorch Lightning callback that creates artifacts for checkpoints.\"\"\"\n",
    "\n",
    "    def __init__(self, run_id: str):\n",
    "        self.run_id = run_id\n",
    "\n",
    "    def on_train_epoch_end(\n",
    "        self, trainer: pl.Trainer, pl_module: pl.LightningModule\n",
    "    ) -> None:\n",
    "        ckpt_path = f\"model_checkpoints/{self.run_id}_last_epoch.ckpt\"\n",
    "        if Path(ckpt_path).exists():\n",
    "            ln.Artifact(\n",
    "                ckpt_path,\n",
    "                key=f\"testmodels/mlflow/{self.run_id}.ckpt\",\n",
    "                kind=\"model\",\n",
    "            ).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "with mlflow.start_run() as mlflow_run:\n",
    "    train_dataset = MNIST(\n",
    "        root=\"./data\", train=True, download=True, transform=ToTensor()\n",
    "    )\n",
    "    train_loader = utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "    autoencoder = LitAutoEncoder(32, 16)\n",
    "\n",
    "    run_id = mlflow_run.info.run_id\n",
    "    ln.context.run.reference = run_id\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"model_checkpoints\",\n",
    "        filename=f\"{run_id}_last_epoch\",\n",
    "        save_top_k=1,\n",
    "        monitor=\"train_loss\",\n",
    "    )\n",
    "    lamindb_callback = LaminDBCheckpointCallback(run_id)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"cpu\",\n",
    "        limit_train_batches=3,\n",
    "        max_epochs=3,\n",
    "        callbacks=[checkpoint_callback, lamindb_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=autoencoder, train_dataloaders=train_loader)\n",
    "\n",
    "    # Register model_summary.txt\n",
    "    local_model_summary_path = (\n",
    "        f\"{mlflow_run.info.artifact_uri.removeprefix('file://')}/model_summary.txt\"\n",
    "    )\n",
    "    mlflow_model_summary_af = ln.Artifact(\n",
    "        local_model_summary_path,\n",
    "        key=f\"testmodels/mlflow/{local_model_summary_path}\",\n",
    "        kind=\"model\",\n",
    "    ).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "**See the training progress in the `mlflow` UI:**\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/C0seowxsq4Du2B4T0000.png\" alt=\"MLFlow training UI\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**See the checkpoints:**\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/n0xxFoMRtZPiQ7VT0001.png\" alt=\"MLFlow checkpoints UI\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "If later on, you want to re-use the checkpoint, you can get it via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "last_checkpoint_af = ln.Artifact.get(\n",
    "    key__startswith=\"testmodels/mlflow/\", suffix__endswith=\"ckpt\", is_latest=True\n",
    ")\n",
    "last_checkpoint_af.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint_af.view_lineage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamindb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
