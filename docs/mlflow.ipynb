{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad6638d",
   "metadata": {},
   "source": [
    "[![](https://img.shields.io/badge/Source%20on%20GitHub-orange)](https://github.com/laminlabs/lamin-mlops/blob/main/docs/mlflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a564bb2",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f834cd3",
   "metadata": {},
   "source": [
    "We show how LaminDB can be integrated with [MLflow](https://mlflow.org/) to track the training process and associate datasets & parameters with models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d25798",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# !pip install 'lamindb[jupyter]' torchvision lightning wandb\n",
    "!lamin init --storage ./lamin-mlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75fb35e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import mlflow\n",
    "import lightning\n",
    "\n",
    "from typing import Any\n",
    "from torch import utils\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from autoencoder import LitAutoEncoder\n",
    "\n",
    "ln.track()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd5cb6",
   "metadata": {},
   "source": [
    "## Define a model\n",
    "\n",
    "We use a basic PyTorch Lightning autoencoder as an example model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf6162",
   "metadata": {},
   "source": [
    "````{dropdown} Code of LitAutoEncoder\n",
    "```{eval-rst}\n",
    ".. literalinclude:: autoencoder.py\n",
    "   :language: python\n",
    "   :caption: Simple autoencoder model\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0c69c",
   "metadata": {},
   "source": [
    "## Query & download the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82194a8",
   "metadata": {},
   "source": [
    "We saved the MNIST dataset in [curation notebook](/mnist) which now shows up in the Artifact registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892070e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(kind=\"dataset\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3793e5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "source": [
    "You can also find it on lamin.ai if you were connected your instance.\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/LlMSvBjHuXbs36TBGoCM.png\" alt=\"instance view\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5675b92c",
   "metadata": {},
   "source": [
    "Let's get the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5ed42",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "mlflow_model_af = ln.Artifact.get(key=\"testdata/mnist\")\n",
    "mlflow_model_af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae0ce2d",
   "metadata": {},
   "source": [
    "And download it to a local cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41faeabe",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "path = mlflow_model_af.cache()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a8d60",
   "metadata": {},
   "source": [
    "Create a PyTorch-compatible dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771f901",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = MNIST(path.as_posix(), transform=ToTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c377f4e9",
   "metadata": {},
   "source": [
    "## Monitor training with MLflow\n",
    "\n",
    "Train our example model and track the training progress with `MLflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mlflow_params(params: dict[str, str]) -> dict[str, Any]:\n",
    "    \"\"\"Concerts MLFlow str parameters to their actual type\"\"\"\n",
    "\n",
    "    def _convert_value(value):\n",
    "        if value == \"None\":\n",
    "            return value\n",
    "        if value.lower() in (\"true\", \"false\"):\n",
    "            return value.lower() == \"true\"\n",
    "        try:\n",
    "            return (\n",
    "                float(value) if (\".\" in value or \"e\" in value.lower()) else int(value)\n",
    "            )\n",
    "        except ValueError:\n",
    "            return value\n",
    "\n",
    "    return {\n",
    "        param_name: _convert_value(param_value)\n",
    "        for param_name, param_value in params.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf383091",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# enable MLFlow PyTorch autologging\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"hidden_size\": 32,\n",
    "    \"bottleneck_size\": 16,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 0.001,\n",
    "    \"eps\": 1e-08,\n",
    "}\n",
    "\n",
    "hyperparameter_type = ln.Feature(name=\"Autoencoder hyperparameter\", is_type=True).save()\n",
    "for param_name, param_value in MODEL_CONFIG.items():\n",
    "    ln.Feature(\n",
    "        name=param_name, dtype=type(param_value).__name__, type=hyperparameter_type\n",
    "    ).save()\n",
    "\n",
    "\n",
    "# Track MLflow run\n",
    "@ln.tracked()\n",
    "def execute_mlflow_run(\n",
    "    hidden_size: int, bottleneck_size: int, batch_size: int\n",
    ") -> ln.Artifact:\n",
    "    with mlflow.start_run() as mlflow_run:\n",
    "        train_dataset = MNIST(\n",
    "            root=\"./data\", train=True, download=True, transform=ToTensor()\n",
    "        )\n",
    "        train_loader = utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "        # Initialize model\n",
    "        autoencoder = LitAutoEncoder(hidden_size, bottleneck_size)\n",
    "\n",
    "        # Create checkpoint callback\n",
    "        from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=\"model_checkpoints\",\n",
    "            filename=f\"{mlflow_run.info.run_id}_last_epoch\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"train_loss\",\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        trainer = lightning.Trainer(\n",
    "            accelerator=\"cpu\",\n",
    "            limit_train_batches=3,\n",
    "            max_epochs=2,\n",
    "            callbacks=[checkpoint_callback],\n",
    "        )\n",
    "\n",
    "        trainer.fit(model=autoencoder, train_dataloaders=train_loader)\n",
    "\n",
    "        # Get run information\n",
    "        run_id = mlflow_run.info.run_id\n",
    "        metrics = mlflow.get_run(run_id).data.metrics\n",
    "        params = mlflow.get_run(run_id).data.params\n",
    "        params = convert_mlflow_params(mlflow.get_run(run_id).data.params)\n",
    "\n",
    "        # Create hyperparameter and metric features\n",
    "        for param_name, param_value in params.items():\n",
    "            if param_name not in MODEL_CONFIG:\n",
    "                ln.Feature(\n",
    "                    name=param_name,\n",
    "                    dtype=type(param_value).__name__,\n",
    "                    type=hyperparameter_type,\n",
    "                ).save()\n",
    "        metric_type = ln.Param(name=\"Autoencoder metric\", is_type=True).save()\n",
    "        ln.Feature(name=\"train_loss\", dtype=\"float\", type=metric_type).save()\n",
    "\n",
    "        local_artifact_path = mlflow_run.info.artifact_uri.removeprefix(\"file://\")\n",
    "\n",
    "        # save model artifacts\n",
    "        mlflow_run_afs = ln.Artifact.from_dir(\n",
    "            local_artifact_path,\n",
    "            key=f\"testmodels/mlflow/{local_artifact_path}\",\n",
    "        )\n",
    "        ln.save(mlflow_run_afs)\n",
    "\n",
    "        # save checkpoint as a model\n",
    "        mlflow_model_af = ln.Artifact(\n",
    "            f\"model_checkpoints/{run_id}_last_epoch.ckpt\",\n",
    "            key=\"testmodels/mlflow/litautoencoder.ckpt\",\n",
    "            kind=\"model\",\n",
    "        ).save()\n",
    "\n",
    "        # annotate artifact with hyperparameters and metrics\n",
    "        mlflow_model_af.features.add_values(params)\n",
    "        mlflow_model_af.features.add_values(metrics)\n",
    "\n",
    "        return mlflow_model_af, mlflow_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62a96f",
   "metadata": {},
   "source": [
    "**See the training progress in the `mlflow` UI:**\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/C0seowxsq4Du2B4T0000.png\" alt=\"MLFlow training UI\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab92c153",
   "metadata": {},
   "source": [
    "## Save model in LaminDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75f27c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "mlflow_model_af, mlflow_run = execute_mlflow_run(\n",
    "    batch_size=MODEL_CONFIG[\"batch_size\"],\n",
    "    bottleneck_size=MODEL_CONFIG[\"bottleneck_size\"],\n",
    "    hidden_size=MODEL_CONFIG[\"hidden_size\"],\n",
    ")\n",
    "\n",
    "# look at Artifact annotations\n",
    "mlflow_model_af.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367d8b0",
   "metadata": {},
   "source": [
    "**See the checkpoints:**\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/n0xxFoMRtZPiQ7VT0001.png\" alt=\"MLFlow checkpoints UI\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331ea1e",
   "metadata": {},
   "source": [
    "If later on, you want to re-use the checkpoint, you can download it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e92101",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.get(key=\"testmodels/mlflow/litautoencoder.ckpt\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4a5e1",
   "metadata": {},
   "source": [
    "Or on the CLI:\n",
    "```\n",
    "lamin get artifact --key 'testmodels/litautoencoder'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becc480",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc136bb",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#!rm -rf ./lamin-mlops\n",
    "#!lamin delete --force lamin-mlops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamindb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
