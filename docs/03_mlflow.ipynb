{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a564bb2",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f834cd3",
   "metadata": {},
   "source": [
    "We show how LaminDB can be integrated with [MLFlow](https://mlflow.org/) to track the training process and associate datasets & parameters with models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d25798",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# !pip install 'lamindb[jupyter]' torchvision lightning wandb\n",
    "!lamin init --storage ./lamin-mlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75fb35e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import mlflow\n",
    "import lightning\n",
    "\n",
    "from torch import utils\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from autoencoder import LitAutoEncoder\n",
    "\n",
    "ln.track()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd5cb6",
   "metadata": {},
   "source": [
    "## Define a model\n",
    "\n",
    "We use a basic PyTorch Lightning autoencoder as an example model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf6162",
   "metadata": {},
   "source": [
    "{dropdown}\n",
    "```{eval-rst}\n",
    ".. literalinclude:: autoencoder.py\n",
    "   :language: python\n",
    "   :caption: Simple autoencoder model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0c69c",
   "metadata": {},
   "source": [
    "## Query & download the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82194a8",
   "metadata": {},
   "source": [
    "We saved the MNIST dataset in [curation notebook](/01_mnist) which now shows up in the Artifact registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892070e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(kind=\"dataset\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3793e5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "source": [
    "You can also find it on lamin.ai if you were connected your instance.\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/LlMSvBjHuXbs36TBGoCM.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5675b92c",
   "metadata": {},
   "source": [
    "Let's get the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5ed42",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "artifact = ln.Artifact.get(key=\"testdata/mnist\")\n",
    "artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae0ce2d",
   "metadata": {},
   "source": [
    "And download it to a local cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41faeabe",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "path = artifact.cache()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a8d60",
   "metadata": {},
   "source": [
    "Create a PyTorch-compatible dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771f901",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = MNIST(path.as_posix(), transform=ToTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c377f4e9",
   "metadata": {},
   "source": [
    "## Monitor training with mlflow\n",
    "\n",
    "Train our example model and track the training progress with `mlflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf383091",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "mlflow.pytorch.autolog()\n",
    "\n",
    "MODEL_CONFIG = {\"hidden_size\": 32, \"bottleneck_size\": 16, \"batch_size\": 32}\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    train_dataset = MNIST(\n",
    "        root=\"./data\", train=True, download=True, transform=ToTensor()\n",
    "    )\n",
    "    train_loader = utils.data.DataLoader(\n",
    "        train_dataset, batch_size=MODEL_CONFIG[\"batch_size\"]\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    autoencoder = LitAutoEncoder(\n",
    "        MODEL_CONFIG[\"hidden_size\"], MODEL_CONFIG[\"bottleneck_size\"]\n",
    "    )\n",
    "\n",
    "    # Create checkpoint callback\n",
    "    from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"model_checkpoints\",\n",
    "        filename=f\"{run.info.run_id}_last_epoch\",\n",
    "        save_top_k=1,\n",
    "        monitor=\"train_loss\",\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    trainer = lightning.Trainer(\n",
    "        accelerator=\"cpu\",\n",
    "        limit_train_batches=3,\n",
    "        max_epochs=2,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=autoencoder, train_dataloaders=train_loader)\n",
    "\n",
    "    # Get run information\n",
    "    run_id = run.info.run_id\n",
    "    metrics = mlflow.get_run(run_id).data.metrics\n",
    "    params = mlflow.get_run(run_id).data.params\n",
    "\n",
    "    # Access model artifacts path\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    artifacts_path = run.info.artifact_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62a96f",
   "metadata": {},
   "source": [
    "**See the training progress in the `mlflow` UI:**\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/C0seowxsq4Du2B4T0000.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab92c153",
   "metadata": {},
   "source": [
    "## Save model in LaminDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75f27c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# save checkpoint as a model in LaminDB\n",
    "artifact = ln.Artifact(\n",
    "    f\"model_checkpoints/{run_id}_last_epoch.ckpt\",\n",
    "    key=\"testmodels/mlflow/litautoencoder.ckpt\",  # is automatically versioned\n",
    "    type=\"model\",\n",
    ").save()\n",
    "\n",
    "# create a label with the mlflow experiment name\n",
    "mlflow_run_name = mlflow.get_run(run_id).data.tags.get(\n",
    "    \"mlflow.runName\", f\"run_{run_id}\"\n",
    ")\n",
    "experiment_label = ln.ULabel(\n",
    "    name=mlflow_run_name, description=\"mlflow experiment name\"\n",
    ").save()\n",
    "\n",
    "# annotate the model Artifact\n",
    "artifact.ulabels.add(experiment_label)\n",
    "\n",
    "# define the associated model hyperparameters in ln.Param\n",
    "for k, v in MODEL_CONFIG.items():\n",
    "    ln.Param(name=k, dtype=type(v).__name__).save()\n",
    "artifact.params.add_values(MODEL_CONFIG)\n",
    "\n",
    "# look at Artifact annotations\n",
    "artifact.describe()\n",
    "artifact.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367d8b0",
   "metadata": {},
   "source": [
    "**See the checkpoints:**\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/n0xxFoMRtZPiQ7VT0001.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331ea1e",
   "metadata": {},
   "source": [
    "If later on, you want to re-use the checkpoint, you can download it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e92101",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.get(key=\"testmodels/mlflow/litautoencoder.ckpt\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4a5e1",
   "metadata": {},
   "source": [
    "Or on the CLI:\n",
    "```\n",
    "lamin get artifact --key 'testmodels/litautoencoder'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becc480",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc136bb",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!rm -rf ./lamin-mlops\n",
    "!lamin delte lamin-mlops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamindb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
