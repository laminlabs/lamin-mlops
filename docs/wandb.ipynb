{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ff2cca",
   "metadata": {},
   "source": [
    "[![](https://img.shields.io/badge/Source%20on%20GitHub-orange)](https://github.com/laminlabs/lamin-mlops/blob/main/docs/wandb.ipynb)\n",
    "[![](https://img.shields.io/badge/Source%20%26%20report%20on%20LaminHub-mediumseagreen)](https://lamin.ai/laminlabs/lamindata/transform/nrPNwWEVUsL95zKv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff135177a7ae90",
   "metadata": {},
   "source": [
    "# Weights & Biases\n",
    "\n",
    "We show how LaminDB can be integrated with W&B to track the training process and associate datasets & parameters with models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1428ec774d35",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# !pip install 'lamindb[jupyter]' torchvision lightning wandb\n",
    "!lamin init --storage ./lamin-mlops\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32efa3d458f7d713",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import wandb\n",
    "import lightning\n",
    "\n",
    "from torch import utils\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from autoencoder import LitAutoEncoder\n",
    "\n",
    "ln.track()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4271521b-0791-4df3-b043-3acc13b3f54c",
   "metadata": {},
   "source": [
    "## Define a model\n",
    "\n",
    "We use a basic PyTorch Lightning autoencoder as an example model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367bf259",
   "metadata": {},
   "source": [
    "````{dropdown} Code of LitAutoEncoder\n",
    "```{eval-rst}\n",
    ".. literalinclude:: autoencoder.py\n",
    "   :language: python\n",
    "   :caption: Simple autoencoder model\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3f68c-6e10-4b95-a4f5-729704690a25",
   "metadata": {},
   "source": [
    "## Query & download the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03ee9c-eadd-479f-beca-ad84e4118a6e",
   "metadata": {},
   "source": [
    "We saved the MNIST dataset in [curation notebook](/mnist) which now shows up in the Artifact registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.Artifact.filter(kind=\"dataset\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19d468",
   "metadata": {},
   "source": [
    "You can also find it on lamin.ai if you were connected your instance.\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/LlMSvBjHuXbs36TBGoCM.png\" alt=\"instance view\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea687f6a",
   "metadata": {},
   "source": [
    "Let's get the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e0bbe9-3429-431b-addf-8f75652c8df9",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "artifact = ln.Artifact.get(key=\"testdata/mnist\")\n",
    "artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524876dd",
   "metadata": {},
   "source": [
    "And download it to a local cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485a6c3",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "path = artifact.cache()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fb6c06",
   "metadata": {},
   "source": [
    "Create a PyTorch-compatible dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c390c0",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = MNIST(path.as_posix(), transform=ToTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605dd3b1-a200-467b-9f3d-3c19dae84495",
   "metadata": {},
   "source": [
    "## Monitor training with wandb\n",
    "\n",
    "Train our example model and track the training progress with `wandb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04e4ae-0c89-46e1-9e55-593bcded67e2",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "MODEL_CONFIG = {\"hidden_size\": 32, \"bottleneck_size\": 16, \"batch_size\": 32}\n",
    "\n",
    "# create the data loader\n",
    "train_loader = utils.data.DataLoader(\n",
    "    dataset, batch_size=MODEL_CONFIG[\"batch_size\"], shuffle=True\n",
    ")\n",
    "\n",
    "# init model\n",
    "autoencoder = LitAutoEncoder(\n",
    "    MODEL_CONFIG[\"hidden_size\"], MODEL_CONFIG[\"bottleneck_size\"]\n",
    ")\n",
    "\n",
    "# initialize the logger\n",
    "wandb_logger = WandbLogger(project=\"lamin\")\n",
    "\n",
    "# add batch size to the wandb config\n",
    "wandb_logger.experiment.config[\"batch_size\"] = MODEL_CONFIG[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d1dee-0e04-4150-898e-deb4e6060f31",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "# store checkpoints to disk and upload to LaminDB after training\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"model_checkpoints/{wandb_logger.version}.ckpt\",\n",
    "    filename=\"last_epoch\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"train_loss\",\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer = lightning.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    limit_train_batches=3,\n",
    "    max_epochs=2,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98ca68-6a6e-4c9d-bbfa-9d31eae2eb76",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "wandb_logger.experiment.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583004ac-aead-4ca5-8043-d5271af934e7",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "wandb_logger.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641b4b6da4ada952",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cddbb5-50a6-4ef9-8534-f4bad6c07af6",
   "metadata": {},
   "source": [
    "**See the training progress in the `wandb` UI:**\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/awrTvbxrLaiNav17VxBN.png\" alt=\"Wandb training ui\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62012e5c-e6bb-4b6e-a0cb-0becf9e495ea",
   "metadata": {},
   "source": [
    "## Save model in LaminDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a85a7-f7e8-4c81-bbe1-050659016d98",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# save checkpoint as a model\n",
    "artifact = ln.Artifact(\n",
    "    f\"model_checkpoints/{wandb_logger.version}.ckpt\",\n",
    "    key=\"testmodels/wandb/litautoencoder.ckpt\",\n",
    "    kind=\"model\",\n",
    ").save()\n",
    "\n",
    "# create a label with the wandb experiment name\n",
    "experiment_label = ln.ULabel(\n",
    "    name=wandb_logger.experiment.name, description=\"wandb experiment name\"\n",
    ").save()\n",
    "\n",
    "# annotate the model artifact\n",
    "artifact.ulabels.add(experiment_label)\n",
    "\n",
    "# define the associated model hyperparameters\n",
    "for k, v in MODEL_CONFIG.items():\n",
    "    ln.Feature(name=k, dtype=type(v).__name__).save()\n",
    "artifact.features.add_values(MODEL_CONFIG)\n",
    "\n",
    "# look at Artifact annotations\n",
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2614158-cc36-4e52-87f4-32151e93b6da",
   "metadata": {},
   "source": [
    "**See the checkpoints:**\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/248fOMXqxT0U4f7LRSgj.png\" alt=\"Wandb check points\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51300c29",
   "metadata": {},
   "source": [
    "If later on, you want to re-use the checkpoint, you can download it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf09a0a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.get(key=\"testmodels/wandb/litautoencoder.ckpt\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83bf6c",
   "metadata": {},
   "source": [
    "Or on the CLI:\n",
    "```\n",
    "lamin get artifact --key 'testmodels/litautoencoder'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0705e2d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamindb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
